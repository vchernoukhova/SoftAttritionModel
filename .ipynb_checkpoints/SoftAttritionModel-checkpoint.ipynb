{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## SET UP ##########################\n",
    "\n",
    "response = 'rvl_ind_drp_prc4'\n",
    "\n",
    "tuning_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rvl_ind_drp_dol2',\n",
       " 'rvl_ind_drp_prc2',\n",
       " 'rvl_ind_drp_dol3',\n",
       " 'rvl_ind_drp_prc3',\n",
       " 'rvl_ind_drp_dol4',\n",
       " 'rvl_ind_drp_prc4',\n",
       " 'rvl_ind_drp_dol5',\n",
       " 'rvl_ind_drp_prc5',\n",
       " 'rvl_ind_drp_dol6',\n",
       " 'rvl_ind_drp_prc6',\n",
       " 'rvl_ind_drp_dol7',\n",
       " 'rvl_ind_drp_prc7']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in initial_variables if 'rvl_ind_drp' in k]\n",
    "# #purchase_attrition_ind\n",
    "# #revolve_attrition_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "import dataiku\n",
    "import dataiku.spark as dkuspark\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re as re\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "#print(sys.version)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from math import log\n",
    "from datetime import datetime, timedelta\n",
    "from numpy import sort\n",
    "\n",
    "import scipy.stats as st\n",
    "import scipy.special as spec\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit,StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, precision_score, recall_score,confusion_matrix, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################ Loading Main Data Set ################################\n",
    "\n",
    "# start = time.time()\n",
    "# model_data_dk = dataiku.Dataset(\"model_data2\")\n",
    "# end = time.time()\n",
    "# print(\"Dataiku execusion: \", int((end - start)/60), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# #get_dataframe(sampling = 'random', ratio = 0.1)\n",
    "# model_data = model_data_dk.get_dataframe()\n",
    "# end = time.time()\n",
    "# print(\"GetDataFrame execusion: \", int((end - start)/60), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################### Loading Cycle Data Set ################################\n",
    "\n",
    "# start = time.time()\n",
    "# model_cycle_data = dataiku.Dataset(\"model_cycle\")\n",
    "# model_cycle = model_cycle_data.get_dataframe()\n",
    "# end = time.time()\n",
    "# print(\"Execution Time for Cycle Data Was: \", (end - start)/60, \"minutes\")\n",
    "\n",
    "# model_cycle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################### Loading Targets Data Set ################################\n",
    "\n",
    "# start = time.time()\n",
    "# multiple_targets_data = dataiku.Dataset(\"multiple_targets2\")\n",
    "# multiple_targets = multiple_targets_data.get_dataframe()\n",
    "# end = time.time()\n",
    "# print(\"Execution Time for Targets Data Was: \", (end - start)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################ Loading Payments Data Set ################################\n",
    "\n",
    "# start = time.time()\n",
    "# model_payments_data = dataiku.Dataset(\"model_payments_data\")\n",
    "# model_payments = model_payments_data.get_dataframe()\n",
    "# end = time.time()\n",
    "# print(\"Execution Time for Payments Data Was: \", (end - start)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################## Getting New Fields from Payments Data ##############################################\n",
    "\n",
    "# ## Group FIs\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('ROYAL|AVION'), 'fi_group' ] = 'rbc'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('CANADIAN TIRE'), 'fi_group' ] = 'cad_tire'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('BANK OF MONTREAL'), 'fi_group' ] = 'bmo'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('CIBC'), 'fi_group' ] = 'cibc'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('TD'), 'fi_group' ] = 'td'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('MBNA'), 'fi_group' ] = 'mbna'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('SCOTIA'), 'fi_group' ] = 'scotia'\n",
    "# model_payments.loc[model_payments['fi_nm'].str.contains('AMERICAN EXPRESS'), 'fi_group' ] = 'amex'\n",
    "\n",
    "# model_payments.loc[model_payments['fi_group'].isnull(), 'fi_group' ] = 'the_rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def months_subtract(input_date,months_to_subtract):\n",
    "    \n",
    "#     input_year = int(input_date/100)\n",
    "#     input_month = input_date%100 \n",
    "    \n",
    "#     if (input_month - months_to_subtract) > 0:\n",
    "#         output_month = input_month - months_to_subtract\n",
    "#         output_year = input_year\n",
    "#     else: \n",
    "#         output_month = (input_month - months_to_subtract) + 12\n",
    "#         output_year = input_year - 1\n",
    "    \n",
    "#     output_date = output_year*100 + output_month\n",
    "        \n",
    "#     return output_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = 201804\n",
    "\n",
    "# last_month = months_subtract(now,1)\n",
    "# three_months_ago = months_subtract(now,3)\n",
    "# six_months_ago =  months_subtract(now,6)\n",
    "# twelve_months_ago =  months_subtract(now,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_balances = pd.DataFrame()\n",
    "\n",
    "# metrics = ['bal_amt', 'cl_amt', 'last_2_mth_spd_amt', 'rvl_bal' ] # and do totals for other metrics, maybe\n",
    "# fi_groups = model_payments.fi_group.unique().tolist() \n",
    "\n",
    "# time_frames = [last_month, three_months_ago, six_months_ago, twelve_months_ago ]\n",
    "# time_frame_names = ['1_month', '3_month_avg', '6_month_avg', '12_month_avg']\n",
    "\n",
    "\n",
    "# for (time_frame, time_frame_name) in zip(time_frames, time_frame_names):\n",
    "    \n",
    "#     #for a certain time period..\n",
    "#     certain_months = pd.DataFrame()\n",
    "#     certain_months = model_payments[(model_payments['ym_id'] >= time_frame) & (model_payments['ym_id'] <= last_month )]\n",
    "    \n",
    "#     #pull all metrics for all FIs..\n",
    "#     for metric in metrics:\n",
    "        \n",
    "#         #save them in \"balances\" data frame..\n",
    "#         balances = pd.DataFrame()\n",
    "#         balances = certain_months[['equifax_id', 'fi_group', metric]\n",
    "#                                  ].groupby(['equifax_id', 'fi_group']).mean().unstack('fi_group').fillna(0).reset_index()\n",
    "\n",
    "#         names_list = [metric + '_' + x + '_' + time_frame_name for x in fi_groups]\n",
    "#         balances.columns = ['equifax_id'] + names_list\n",
    "\n",
    "#         #and then join it back to the big dataframe \"fi_balances\" that will store all these metrics for all the loops\n",
    "#         if fi_balances.shape[0] == 0:\n",
    "#             fi_balances = balances\n",
    "#         else:\n",
    "#             fi_balances = fi_balances.merge(balances, on = ['equifax_id'], how = 'outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(fi_balances) #rvl_bal_bmo_3month_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data_fi = model_data.merge(fi_balances, on = ['equifax_id'], how  = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #how many missing ocifs\n",
    "# model_data_fi['ocif_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data_exclusions = model_data_fi.loc[(model_data_fi['ocif_id'].isnull() == False)\n",
    "#                                            & (model_data_fi['rvl_now_ind'] == 1)\n",
    "#                                            & (model_data_fi['num_total_mnth'] == 12)\n",
    "#                                            & (model_data_fi['num_pos_rvl_mnth']>5), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('After the exclusion criteria, we reduced size of the data from', model_data.shape[0] ,\n",
    "#        \"rows to\", model_data_exclusions.shape[0], 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = model_data_exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# EXPORTED DATA AS VC_ATTRITION_MODEL TABLE ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time:  1 minutes\n"
     ]
    }
   ],
   "source": [
    "#importing the whole dataset for modelling\n",
    "\n",
    "start = time.time()\n",
    "data_dk = dataiku.Dataset(\"vc_attrition_model\")\n",
    "data = data_dk.get_dataframe()\n",
    "end = time.time()\n",
    "print(\"Execution Time: \", int((end - start)/60), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time:  0 minutes\n"
     ]
    }
   ],
   "source": [
    "#importing dataset with different targets\n",
    "\n",
    "start = time.time()\n",
    "targets_dk = dataiku.Dataset(\"vc_multiple_targets\")\n",
    "targets = targets_dk.get_dataframe()\n",
    "end = time.time()\n",
    "print(\"Execution Time: \", int((end - start)/60), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data with newly added targets\n",
    "data = data.merge(targets, on = ['mba_acct_nbr'], how = 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736001, 450)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_variables = list(data)\n",
    "variables_include_future = ['revolve_attrition_ind', 'purchase_attrition_ind'] + [k for k in initial_variables if 'rvl_ind_drp' in k]\n",
    "variables_include_future.remove(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['mba_acct_nbr','revolve_attrition_ind']].groupby('revolve_attrition_ind', as_index = False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of variables that have NULL values\n",
    "all_variables = list(data)\n",
    "nullval_variables = list()\n",
    "\n",
    "for variable in all_variables:\n",
    "    if data[variable].isnull().sum() > 0:\n",
    "        nullval_variables.append(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Treat NULL with O ###########################\n",
    "\n",
    "#create a list to treat variables to be 0 instead of NULLs\n",
    "null_means_zero = ['bal', 'cnt', 'amt', 'nbr']\n",
    "zero_for_null_variables = list()\n",
    "\n",
    "for variable in nullval_variables:\n",
    "    if any([x in variable for x in null_means_zero]):\n",
    "        zero_for_null_variables.append(variable)\n",
    "        \n",
    "        \n",
    "#some of them we don't want to treat with 0\n",
    "to_remove = ['cntry_cd']\n",
    "for item in to_remove:\n",
    "    zero_for_null_variables.remove(item)\n",
    "    \n",
    "\n",
    "# treat with zero\n",
    "data = data.copy()\n",
    "for variable in zero_for_null_variables:\n",
    "    data[variable].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_for_null_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun check for how many variables have NULL after treating many of them with 0\n",
    "all_variables = list(data)\n",
    "nullval_variables = list()\n",
    "\n",
    "for variable in all_variables:\n",
    "    if data[variable].isnull().sum() > 0:\n",
    "        nullval_variables.append(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nullval_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get variables that have nulls\n",
    "null_counts = data.isnull().sum().reset_index()\n",
    "variables_have_nulls = list(null_counts.loc[null_counts[0]>0,:]['index'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and some other variables you want to delete\n",
    "variables_not_needed = ['mth_indvdl_inc_amt', 'mth_hshld_inc_amt']\n",
    "variable_ids =  ['ocif_id','cad_acct_id', 'mba_acct_nbr_cus']\n",
    "variables_constants = ['num_total_mnth','rvl_now_ind' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all of them\n",
    "variables_to_delete = variables_have_nulls + variables_include_future + variables_not_needed + variable_ids + variables_constants\n",
    "\n",
    "for variable in variables_to_delete:\n",
    "    data = data.drop(variable,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#variables_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new variables on balances and transactions\n",
    "balance_variables = ['cl_amt', 'crn_bal', 'olim_amt', 'pymt_cnt', 'pymt_amt', 'ccar_net_pur_amt', 'ccar_net_cash_amt',\n",
    "                    'cyc_low_bal_amt','cyc_high_bal_amt', 'bal_rvl_amt' ]\n",
    "\n",
    "transaction_variables = ['total_txn_amt', 'total_txn_cnt', 'fdbvr_txn_amt', 'grcry_txn_amt', 'gas_txn_amt', \n",
    "                         'clth_txn_amt', 'trvl_txn_amt' ]\n",
    "\n",
    "first_mnth = ['3','6']\n",
    "second_mnth = ['6', '12']\n",
    "\n",
    "for variable in balance_variables + transaction_variables:\n",
    "    for (first,second) in zip(first_mnth,second_mnth):\n",
    "        \n",
    "        divident = variable + '_'+ first +'month_avg'\n",
    "        divisor = variable + '_'+ second +'month_avg'\n",
    "        new_variable = variable + '_'+ first + '_'+ second +'month_avg'\n",
    "\n",
    "        data.loc[data[divisor] !=0 ,new_variable]= data [divident]/data[divisor]\n",
    "        data.loc[data[divisor] == 0 ,new_variable] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new variables on payments data\n",
    "variables = ['rvl_bal','last_2_mth_spd_amt', 'cl_amt', 'bal_amt']\n",
    "fis = ['rbc','cad_tire', 'bmo', 'cibc', 'td', 'mbna', 'scotia', 'amex', 'the_rest'] \n",
    "\n",
    "first_mnth = ['3','6']\n",
    "second_mnth = ['6', '12']\n",
    "\n",
    "for variable in variables:\n",
    "    for (first, second) in zip(first_mnth,second_mnth):\n",
    "        for fi in fis:\n",
    "            \n",
    "            divident = variable + '_'+ fi + '_' + first + '_' +'month_avg'\n",
    "            divisor = variable + '_'+ fi + '_' + second + '_' +'month_avg'\n",
    "            new_variable = variable + '_'+ fi + '_' + first + '_'+ second +'month_avg'\n",
    "\n",
    "            data.loc[data[divisor] !=0 ,new_variable]= data [divident]/data[divisor]\n",
    "            data.loc[data[divisor] == 0 ,new_variable] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rvl_bal_bmo_6_12month_avg\n",
    "# variables = list(data)\n",
    "# bmo_variables = list()\n",
    "# for variable in variables:\n",
    "#     if ('the_rest' in variable):\n",
    "#         bmo_variables.append(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort(bmo_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new \n",
    "metrics = ['bal_amt', 'cl_amt', 'last_2_mth_spd_amt', 'rvl_bal']\n",
    "fis = ['rbc','cad_tire', 'cibc', 'td', 'mbna', 'scotia', 'amex', 'the_rest']  #, 'bmo'\n",
    "timelines = ['1_month','3_month_avg', '6_month_avg', '12_month_avg', '3_6month_avg', '6_12month_avg']\n",
    "\n",
    "for metric in metrics:\n",
    "    for timeline in timelines:\n",
    "        \n",
    "        all_field_name = metric + '_all_' + timeline\n",
    "        data[all_field_name] = 0\n",
    "        \n",
    "        for fi in fis:\n",
    "            \n",
    "            fi_field_name = metric + '_' + fi + '_' + timeline\n",
    "            data[all_field_name] += data[fi_field_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all indicators to be categorical variables except the response\n",
    "all_variables = list(data)\n",
    "all_variables.remove(response)\n",
    "\n",
    "to_type = 'object'\n",
    "for variable in all_variables:\n",
    "    if 'ind' in variable:\n",
    "        data.loc[:,variable] = data[variable].astype(to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('mba_acct_nbr', inplace=True)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############# logging variables ##################\n",
    "# non_cat_var = data.select_dtypes(include = ['int64', 'float64']).columns.tolist()\n",
    "# non_cat_var.remove(response)\n",
    "\n",
    "# for variable in non_cat_var:\n",
    "#     min_value =  data[variable].min() \n",
    "#     data[variable] = data[variable].apply(lambda x: log(x+1-min_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.loc[:,response]\n",
    "X = data.drop (response, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = 768\n",
    "test_prc = 0.3\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size = test_prc, random_state = random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = X_train\n",
    "data_train[response] = y_train\n",
    "\n",
    "data_test = X_test\n",
    "data_test[response] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(data, to_print):\n",
    "    \n",
    "    categorical_variables = data.select_dtypes(include = ['category', 'object']).columns.tolist()\n",
    "    dummy_variables = pd.get_dummies(data.loc[:,categorical_variables], drop_first = True)\n",
    "\n",
    "    data = pd.merge(data, dummy_variables, left_index = True, right_index = True)\n",
    "    data_out = data.drop(categorical_variables, axis = 1)\n",
    "    \n",
    "    if to_print == 1:\n",
    "    \n",
    "        print (\"List of all categorical variables: \", \"\\n\")\n",
    "        print (*categorical_variables, sep = \"\\n\")\n",
    "        print (\" \")\n",
    "\n",
    "        print (\"After creating dummy variables, the list looks like this: \", \"\\n\")\n",
    "        print ( *data_out.columns.tolist(), sep = \"\\n\")\n",
    "        print (\" \")\n",
    "        \n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = create_dummies(data_train,0)\n",
    "data_test = create_dummies(data_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = list (data_train)\n",
    "all_variables.remove(response)\n",
    "\n",
    "supes_important = ['rvl_bal_the_rest_1_month', 'cr_crd_tot_bal', 'total_txn_amt_12month_avg']\n",
    "#important_from_model = pd.Series(best_classifier.feature_importances_, index=X_test.columns).nlargest(5).reset_index()['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### AB Featue Selection ########################################\n",
    "\n",
    "\n",
    "y_train = data_train.loc[:, response]\n",
    "X_train = data_train.loc[:, all_variables]\n",
    "\n",
    "treeCL = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "treeCL = treeCL.fit(X_train,y_train)\n",
    "\n",
    "model = SelectFromModel(treeCL,prefit=True)\n",
    "\n",
    "mask = model.get_support()\n",
    "important_variables = X_train.columns[mask]\n",
    "\n",
    "\n",
    "######################### VC Featue Selection ########################################\n",
    "\n",
    "# X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(X_train, y_train, test_size=0.30, random_state = 1209)\n",
    "\n",
    "# model = ExtraTreesClassifier() \n",
    "# model.fit(X_train_fs, y_train_fs)\n",
    "\n",
    "\n",
    "# # make predictions for test data and evaluate\n",
    "# y_pred_fs = model.predict(X_test_fs)\n",
    "\n",
    "# accuracy = accuracy_score(y_test_fs, y_pred_fs)\n",
    "# print(\"Accuracy:\", (accuracy * 100.0))\n",
    "\n",
    "# # Fit model using each importance as a threshold\n",
    "# #thresholds = sort(np.random.uniform(1e-4,1e-2,10)) #sort(model.feature_importances_)\n",
    "# thresholds = []\n",
    "\n",
    "# for thresh in thresholds:\n",
    "    \n",
    "#     # select features using threshold\n",
    "#     selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "#     select_X_train_fs = selection.transform(X_train_fs)\n",
    "    \n",
    "#     # train model\n",
    "#     selection_model = ExtraTreesClassifier() \n",
    "#     selection_model.fit(select_X_train_fs, y_train_fs)\n",
    "    \n",
    "#     # eval model\n",
    "#     select_X_test_fs = selection.transform(X_test_fs)\n",
    "#     y_pred_fs = selection_model.predict(select_X_test_fs)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test_fs, y_pred_fs)\n",
    "#     roc_auc = roc_auc_score(y_test_fs, y_pred_fs)\n",
    "#     print(\"Thresh=%.3f, n=%d, ROC: %.2f%%\" % (thresh, select_X_train_fs.shape[1], roc_auc*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can use all_variables, important_variables, or supes_important \n",
    "\n",
    "variables_to_include = important_variables\n",
    "\n",
    "y_train = data_train.loc[:, response]\n",
    "X_train = data_train.loc[:, variables_to_include]\n",
    "\n",
    "y_test = data_test.loc[:, response]\n",
    "X_test = data_test.loc[:, variables_to_include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################ TUNNING GRADIENT BOOSTING ################################################ \n",
    "\n",
    "# #https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "# # consider using GridSearchCV\n",
    "\n",
    "# gb = GradientBoostingClassifier()\n",
    "\n",
    "# row_num = X_train.shape[0]\n",
    "\n",
    "# learning_rate_start = 0.1 #0.03\n",
    "# learning_rate_end = 0.4 #0.3\n",
    "\n",
    "# n_estimators_start = 3\n",
    "# n_estimators_end =  40 \n",
    "\n",
    "# max_depth_start = 3\n",
    "# max_depth_end = 40 \n",
    "\n",
    "# # min_samples_split_start = round(0.01*row_num)\n",
    "# # min_samples_split_end = round(0.03*row_num)\n",
    "\n",
    "# # min_samples_leaf_start = 1\n",
    "# # min_samples_leaf_end = 20 \n",
    "\n",
    "\n",
    "# random_grid = {  \n",
    "#                 \"learning_rate\": st.uniform (learning_rate_start, learning_rate_end),\n",
    "#                 \"n_estimators\": st.randint (n_estimators_start, n_estimators_end),\n",
    "#                 \"max_depth\": st.randint (max_depth_start, max_depth_end)\n",
    "#             }\n",
    "\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# gb_random = RandomizedSearchCV(estimator = gb, \n",
    "#                                            param_distributions = random_grid, \n",
    "#                                            n_iter = 10, cv = 3, scoring = 'f1', verbose=True, \n",
    "#                                            random_state=342, n_jobs =-1)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# gb_random.fit(X_train,y_train)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "# GradientBoostingClassifierTuned = GradientBoostingClassifier()\n",
    "# GradientBoostingClassifierTuned.set_params(**gb_random.best_params_)\n",
    "# GradientBoostingClassifierTuned.get_params()\n",
    "# ############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifierTuned = GradientBoostingClassifier(learning_rate = 0.2284706627804977,\n",
    "#                                                              max_depth = 22,\n",
    "#                                                              n_estimators= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### XGB Parameter Tunning ################\n",
    "\n",
    "# #https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "# # consider using GridSearchCV\n",
    "\n",
    "# xgb = XGBClassifier()\n",
    "\n",
    "# row_num = X_train.shape[0]\n",
    "\n",
    "# learning_rate_start = 0.05\n",
    "# learning_rate_end = 0.4\n",
    "\n",
    "# n_estimators_start = 3\n",
    "# n_estimators_end =  40\n",
    "\n",
    "# max_depth_start = 3\n",
    "# max_depth_end = 40\n",
    "\n",
    "# one_to_left = st.beta(10, 1)  \n",
    "# from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "\n",
    "# random_grid = {  \n",
    "#     \"n_estimators\": st.randint(n_estimators_start, n_estimators_end),\n",
    "#     \"max_depth\": st.randint(3, 100),\n",
    "#     \"learning_rate\": st.uniform(learning_rate_start, learning_rate_end)\n",
    "# #    \"colsample_bytree\": one_to_left,\n",
    "# #    \"subsample\": one_to_left,\n",
    "# #    \"gamma\": st.uniform(0, 10),\n",
    "# #    'reg_alpha': from_zero_positive,\n",
    "# #    \"min_child_weight\": from_zero_positive,\n",
    "# }\n",
    "\n",
    "# # random_grid = {  \n",
    "# #     \"n_estimators\": st.randint(n_estimators_start, n_estimators_end),\n",
    "# #     \"max_depth\": st.randint(max_depth_start, max_depth_end),\n",
    "# #     \"learning_rate\": st.uniform(learning_rate_start, learning_rate_end),\n",
    "# #     \"colsample_bytree\": one_to_left,\n",
    "# #     \"subsample\": one_to_left,\n",
    "# #     \"gamma\": st.uniform(0, 10),\n",
    "# #     'reg_alpha': from_zero_positive,\n",
    "# #     \"min_child_weight\": from_zero_positive\n",
    "# # }\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# xgb_random = RandomizedSearchCV(estimator = xgb, \n",
    "#                                            param_distributions = random_grid, \n",
    "#                                            n_iter = 50, cv = 10, scoring = 'f1', verbose=False, \n",
    "#                                            random_state=42)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# xgb_random.fit(X_train,y_train)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "# XGBClassifierTuned = XGBClassifier()\n",
    "# XGBClassifierTuned.set_params(**xgb_random.best_params_)\n",
    "# XGBClassifierTuned.get_params()\n",
    "# #####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### Light GBM Parameter Tunning ################\n",
    "\n",
    "# lgb = LGBMClassifier()\n",
    "\n",
    "# #row_num = X_train.shape[0]\n",
    "\n",
    "# random_grid = {  \n",
    "#     \"num_leaves\": st.randint(3,  1000),\n",
    "#     \"max_depth\": st.randint(3, 100),\n",
    "#     \"min_data_in_leaf\": st.randint(50, 5000)\n",
    "# }\n",
    "\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# lgb_random = RandomizedSearchCV(estimator = lgb, \n",
    "#                                            param_distributions = random_grid, \n",
    "#                                            n_iter = 50, cv = 10, scoring = 'f1', verbose=False, \n",
    "#                                            random_state=42)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# lgb_random.fit(X_train,y_train)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "# LGBMClassifierTuned = LGBMClassifier()\n",
    "# LGBMClassifierTuned.set_params(**lgb_random.best_params_)\n",
    "# #LGBMClassifierTuned.get_params()\n",
    "# #####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### Random Forest Parameter Tunning ################\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# #rf.get_params()\n",
    "\n",
    "# row_num = X_train.shape[0]\n",
    "\n",
    "# n_estimators_start = 5\n",
    "# n_estimators_end =  150\n",
    "\n",
    "# max_depth_start = 5\n",
    "# max_depth_end = 40\n",
    "\n",
    "# # min_samples_split_start =  round(0.01*row_num) #2\n",
    "# # min_samples_split_end = round(0.03*row_num) #10\n",
    "\n",
    "# min_samples_leaf_start = 2\n",
    "# min_samples_leaf_end = 40\n",
    "\n",
    "\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': st.randint (n_estimators_start, n_estimators_end),\n",
    "#                'max_depth': st.randint (max_depth_start, max_depth_end),\n",
    "#                'min_samples_leaf': st.randint (min_samples_leaf_start, min_samples_leaf_end)\n",
    "#               }\n",
    "\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, \n",
    "#                                            param_distributions = random_grid, \n",
    "#                                            n_iter = 50, cv = 5, scoring = 'recall', verbose=True, \n",
    "#                                            random_state=42)\n",
    "\n",
    "# start = time.time()\n",
    "# rf_random.fit(X_train,y_train)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "# RandomForestClassifierTuned = RandomForestClassifier()\n",
    "# RandomForestClassifierTuned.set_params(**rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostingClassifier  - 50 roc on training #####slow\n",
    "#Random Forest: 91.84 roc on training #######fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier =  GradientBoostingClassifier() #RandomForestClassifier() # GradientBoostingClassifier() XGBClassifier() \n",
    "\n",
    "start = time.time()\n",
    "best_classifier.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "model_ran = int(end - start)\n",
    "\n",
    "print(\"Execution Time Was: \", model_ran, \"seconds\")\n",
    "\n",
    "y_pred_test = best_classifier.predict(X_test)\n",
    "y_pred_train = best_classifier.predict(X_train)\n",
    "\n",
    "y_pred_prob_test = best_classifier.predict_proba(X_test)\n",
    "y_pred_prob_train = best_classifier.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = round(100*accuracy_score(y_test, y_pred_test),2)\n",
    "acc_train = round(100*accuracy_score(y_train, y_pred_train),2)\n",
    "\n",
    "roc_test = round(100*roc_auc_score(y_test, y_pred_test),2)\n",
    "roc_train = round(100*roc_auc_score(y_train, y_pred_train),2)\n",
    "\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_pred_train).ravel()\n",
    "\n",
    "recall_test = round(100*tp_test/(tp_test+fn_test),2)\n",
    "precision_test = round(100*tp_test/(tp_test+fp_test),2)\n",
    "\n",
    "recall_train = round(100*tp_train/(tp_train+fn_train),2)\n",
    "precision_train = round(100*tp_train/(tp_train+fp_train),2)\n",
    "\n",
    "print(\n",
    "       \" Accuracy on Testing:\", acc_test, \"%\\n\", \n",
    "       \"ROC on Testing:\", roc_test, \"%\\n\",\n",
    "      \"Recall on Testing:\",recall_test, \"%\\n\",\n",
    "      \"Precision on Testing:\", precision_test, \"%\\n\",\n",
    "      \"##############################\", \"\\n\",\n",
    "      \"Accuracy on Training:\", acc_train, \"%\\n\",\n",
    "      \"ROC on Training: \", roc_train, \"%\\n\",\n",
    "      \"Recall on Training:\", recall_train, \"%\\n\",\n",
    "      \"Precision on Training:\", precision_train, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['Run_date', 'Response', 'Method', 'Tuning', 'n_estimators', 'max_depth', 'min_samples_leaf',\n",
    "                                  'learning_rate','Variables', 'Most_important_var',\n",
    "                                  'Importance_of_it', 'Test_prc', 'Model_ran_sec',\n",
    "                                 'Recall_train', 'Recall_test', 'Precision_train', 'Precision_test',\n",
    "                                 'Accuracy_train', 'Accuracy_test', 'ROC_train', 'ROC_test'\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some metrics for the results table\n",
    "\n",
    "method =  str(type(best_classifier))\n",
    "method = method.split('.')[3].replace(\">\", \"\").replace(\"'\", \"\")\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "most_important = pd.Series(best_classifier.feature_importances_,\n",
    "                           index=X_test.columns).nlargest(1).reset_index()['index'].tolist()[0]\n",
    "\n",
    "its_importance = pd.Series(best_classifier.feature_importances_,\n",
    "                           index=X_test.columns).nlargest(1).reset_index()[0].tolist()[0]\n",
    "\n",
    "parameters = str(best_classifier.get_params()).split(',')\n",
    "\n",
    "n_estimators = [k for k in parameters if 'n_estimators' in k][0].split(':')[1].replace(' ','')\n",
    "max_depth = [k for k in parameters if 'max_depth' in k][0].split(':')[1].replace(' ','')\n",
    "min_samples_leaf = [k for k in parameters if 'min_samples_leaf' in k][0].split(':')[1].replace(' ','')\n",
    "learning_rate = [k for k in parameters if 'learning_rate' in k][0].split(':')[1].replace(' ','')\n",
    "\n",
    "#add a new record in the results table\n",
    "\n",
    "results = results.append({'Run_date': now,\n",
    "                'Response': response,\n",
    "                'Method': method,\n",
    "                'Tuning': tuning_ind,\n",
    "                'n_estimators':n_estimators,\n",
    "                'max_depth':max_depth,\n",
    "                'min_samples_leaf':min_samples_leaf,\n",
    "                'learning_rate':learning_rate,\n",
    "                'Variables': variables_to_include.shape[0],\n",
    "                'Most_important_var':most_important,\n",
    "                'Importance_of_it': its_importance,\n",
    "                'Test_prc':test_prc,\n",
    "                'Model_ran_sec': model_ran,\n",
    "                'Recall_train':recall_train,\n",
    "                'Recall_test': recall_test,\n",
    "                'Precision_train':precision_train,\n",
    "                'Precision_test':precision_test,\n",
    "                'Accuracy_train': acc_train,\n",
    "                'Accuracy_test': acc_test,\n",
    "                'ROC_train':roc_train,\n",
    "                'ROC_test':roc_test\n",
    "               }, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dk = dataiku.Dataset(\"results\")\n",
    "results = results_dk.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Display Decision Tree ###################\n",
    "# from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "# from sklearn import tree\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from graphviz import Source\n",
    "# from IPython.display import display\n",
    "\n",
    "#estimator = best_classifier.estimators_[5]\n",
    "# graph = Source(tree.export_graphviz(estimator, out_file=None, filled = True))\n",
    "# display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = plot_importance(best_classifier, max_num_features=15)\n",
    "features_plot = pd.Series(best_classifier.feature_importances_, index=X_test.columns).nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ROC Curve: Test\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_test[:,1])\n",
    "\n",
    "# plt.clf()\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlabel('FPR')\n",
    "# plt.ylabel('TPR')\n",
    "# plt.title('ROC curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ROC Curve: Train\n",
    "# fpr, tpr, thresholds = roc_curve(y_train, y_pred_train[:,1])\n",
    "\n",
    "# plt.clf()\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlabel('FPR')\n",
    "# plt.ylabel('TPR')\n",
    "# plt.title('ROC curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tn_test, fp_test, fn_test, tp_test )"
   ]
  }
 ],
 "metadata": {
  "creator": "vcherno",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
